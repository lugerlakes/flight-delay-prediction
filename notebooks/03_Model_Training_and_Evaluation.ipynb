{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94dfd3ec",
   "metadata": {},
   "source": [
    "## Stage 3: Model Training, Cost-Sensitive Learning, and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278bb918",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Implement a robust ML pipeline using ColumnTransformer, apply\n",
    "cost-sensitive techniques to handle the class imbalance (18.49% delay rate),\n",
    "and justify the optimal model based on the operational metric, RECALL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e977fdec",
   "metadata": {},
   "source": [
    "### 1. Configuration and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccedaf8",
   "metadata": {},
   "source": [
    "### 2. Load Data and Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b753c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from interim with 68206 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferna\\AppData\\Local\\Temp\\ipykernel_7628\\4094915579.py:2: DtypeWarning: Columns (1,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/interim/02_feature_engineered_data.csv', parse_dates=['fecha_i', 'fecha_o'])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../data/interim/02_feature_engineered_data.csv', parse_dates=['fecha_i', 'fecha_o'])\n",
    "    print(f\"Data loaded from interim with {len(df)} rows.\")\n",
    "except FileNotFoundError:\n",
    "    raise SystemExit(\"Data loading failed. Cannot proceed to Stage 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db56efd",
   "metadata": {},
   "source": [
    "### 3. Data Split and Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 54564 | Test set size: 13642\n"
     ]
    }
   ],
   "source": [
    "FEATURES = ['month', 'dianom', 'tipovuelo', 'opera', 'siglades', 'period_day', \n",
    "            'tavg', 'tavg_is_missing', \n",
    "            'opera_historical_delay_rate', 'dest_historical_delay_rate'] \n",
    "TARGET = 'delay_15'\n",
    "\n",
    "# Drop rows where 'opera_historical_delay_rate' might be NaN (due to lack of historical data)\n",
    "df_model = df.dropna(subset=FEATURES).copy() \n",
    "X = df_model[FEATURES]\n",
    "y = df_model[TARGET]\n",
    "\n",
    "# Stratified Split: Ensures the 18.49% delay rate is maintained in both sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nTraining set size: {len(X_train)} | Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e245cd",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing Pipeline (ColumnTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c570c7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessor fitted, transformed data, and saved for deployment.\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['dianom', 'tipovuelo', 'opera', 'siglades', 'period_day']\n",
    "numeric_features = ['month', 'tavg', 'tavg_is_missing', 'opera_historical_delay_rate', 'dest_historical_delay_rate']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features), # Scale numerical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features) # OHE categorical features\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply the preprocessor and save it for deployment \n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "joblib.dump(preprocessor, '../models/preprocessor_final.pkl')\n",
    "print(\"\\nPreprocessor fitted, transformed data, and saved for deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3bb3bc",
   "metadata": {},
   "source": [
    "### 4. Model Training with Cost-Sensitive Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc8f9d",
   "metadata": {},
   "source": [
    "- Function to calculate scale_pos_weight for tree models (XGBoost)\n",
    "- Weight = (Count of Negative Samples / Count of Positive Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928146bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated scale_pos_weight for XGBoost: 4.41\n",
      "Trained Logistic_Regression.\n",
      "Trained Random_Forest.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ferna\\OneDrive\\Documents\\GitHub\\flight-delay-prediction\\flight_delay_prediction\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [10:21:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained XGBoost.\n"
     ]
    }
   ],
   "source": [
    "scale_pos_weight = (y_train.value_counts()[0] / y_train.value_counts()[1])\n",
    "print(f\"Calculated scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "models = {\n",
    "    # Use class_weight='balanced' to address class imbalance for linear/non-parametric models\n",
    "    \"Logistic_Regression\": LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced'),\n",
    "    \"Random_Forest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    \n",
    "    # Use scale_pos_weight for XGBoost\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "y_probas = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_probas[name] = model.predict_proba(X_test_processed)[:, 1]\n",
    "    print(f\"Trained {name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e78e1f",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a2167f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model: Logistic_Regression (Threshold: 0.50) ---\n",
      "ROC AUC: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.64      0.74     11119\n",
      "           1       0.27      0.58      0.37      2523\n",
      "\n",
      "    accuracy                           0.63     13642\n",
      "   macro avg       0.57      0.61      0.55     13642\n",
      "weighted avg       0.76      0.63      0.67     13642\n",
      "\n",
      "\n",
      "--- Model: Random_Forest (Threshold: 0.50) ---\n",
      "ROC AUC: 0.6353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.87     11119\n",
      "           1       0.32      0.20      0.25      2523\n",
      "\n",
      "    accuracy                           0.77     13642\n",
      "   macro avg       0.58      0.55      0.56     13642\n",
      "weighted avg       0.74      0.77      0.75     13642\n",
      "\n",
      "\n",
      "--- Model: XGBoost (Threshold: 0.50) ---\n",
      "ROC AUC: 0.6914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78     11119\n",
      "           1       0.31      0.59      0.40      2523\n",
      "\n",
      "    accuracy                           0.68     13642\n",
      "   macro avg       0.59      0.64      0.59     13642\n",
      "weighted avg       0.78      0.68      0.71     13642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_test, y_proba, model_name, threshold=0.5):\n",
    "    y_pred = (y_proba > threshold).astype(int)\n",
    "    print(f\"\\n--- Model: {model_name} (Threshold: {threshold:.2f}) ---\")\n",
    "    \n",
    "    # Senior Rationale: For alerting, Recall is primary.\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Evaluate models with cost-sensitive settings at default threshold (0.5)\n",
    "for name, y_proba in y_probas.items():\n",
    "    evaluate_model(y_test, y_proba, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736583af",
   "metadata": {},
   "source": [
    "#### 5.1 Threshold Tuning (Operational Decision-Making)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ee3b858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model: Logistic Regression (Tuned for High Recall) (Threshold: 0.35) ---\n",
      "ROC AUC: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.22      0.35     11119\n",
      "           1       0.21      0.91      0.34      2523\n",
      "\n",
      "    accuracy                           0.35     13642\n",
      "   macro avg       0.56      0.56      0.35     13642\n",
      "weighted avg       0.79      0.35      0.35     13642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot Precision-Recall curve to find the optimal operational point.\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_probas['Logistic_Regression'])\n",
    "\n",
    "# We aim for an operationally acceptable Recall (e.g., 65%) with the best possible Precision.\n",
    "# Plotting helps, but we can programmatically find a point or use a justified value.\n",
    "# Let's use a lower threshold (0.35) often needed for high recall in imbalanced datasets.\n",
    "optimal_threshold_lr = 0.35\n",
    "\n",
    "evaluate_model(y_test, y_probas['Logistic_Regression'], \"Logistic Regression (Tuned for High Recall)\", threshold=optimal_threshold_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5df51",
   "metadata": {},
   "source": [
    "### 5.2 Final Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d5e7772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ferna\\OneDrive\\Documents\\GitHub\\flight-delay-prediction\\flight_delay_prediction\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [10:29:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# Create and train the Voting Classifier ensemble for robustness.\n",
    "final_model = VotingClassifier(\n",
    "    estimators=[(n, models[n]) for n in models.keys()], \n",
    "    voting='soft', \n",
    "    weights=[1, 1, 1]\n",
    ")\n",
    "final_model.fit(X_train_processed, y_train)\n",
    "final_y_proba = final_model.predict_proba(X_test_processed)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b0e2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model: Final Voting Classifier Ensemble (Threshold: 0.50) ---\n",
      "ROC AUC: 0.6839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86     11119\n",
      "           1       0.36      0.34      0.35      2523\n",
      "\n",
      "    accuracy                           0.76     13642\n",
      "   macro avg       0.60      0.60      0.60     13642\n",
      "weighted avg       0.76      0.76      0.76     13642\n",
      "\n",
      "\n",
      "Final Voting Classifier saved to /models/voting_classifier_final.pkl.\n",
      "XGBoost model saved separately for Feature Importance analysis in Stage 4.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final robust ensemble\n",
    "evaluate_model(y_test, final_y_proba, \"Final Voting Classifier Ensemble\")\n",
    "joblib.dump(final_model, '../models/voting_classifier_final.pkl')\n",
    "joblib.dump(models['XGBoost'], '../models/xgb_final.pkl')\n",
    "\n",
    "print(\"\\nFinal Voting Classifier saved to /models/voting_classifier_final.pkl.\")\n",
    "print(\"XGBoost model saved separately for Feature Importance analysis in Stage 4.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flight_delay_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
